{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp('At midnight the doorbell rang, startling him fearfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At at ADP\n",
      "midnight midnight NOUN\n",
      "the the DET\n",
      "doorbell doorbell NOUN\n",
      "rang rang NOUN\n",
      ", , PUNCT\n",
      "startling startle VERB\n",
      "him he PRON\n",
      "fearfully fearfully ADV\n",
      ". . PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc: \n",
    "    print(token.text, token.lemma_, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"4bb57a53bbe545b982cfaa9627766ad9-0\" class=\"displacy\" width=\"1450\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">At</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">midnight</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">doorbell</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">rang,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">startling</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">him</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">fearfully.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4bb57a53bbe545b982cfaa9627766ad9-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,2.0 925.0,2.0 925.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4bb57a53bbe545b982cfaa9627766ad9-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4bb57a53bbe545b982cfaa9627766ad9-0-1\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4bb57a53bbe545b982cfaa9627766ad9-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M210.0,354.0 L218.0,342.0 202.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4bb57a53bbe545b982cfaa9627766ad9-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,177.0 740.0,177.0 740.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4bb57a53bbe545b982cfaa9627766ad9-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4bb57a53bbe545b982cfaa9627766ad9-0-3\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4bb57a53bbe545b982cfaa9627766ad9-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4bb57a53bbe545b982cfaa9627766ad9-0-4\" stroke-width=\"2px\" d=\"M70,352.0 C70,89.5 745.0,89.5 745.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4bb57a53bbe545b982cfaa9627766ad9-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">meta</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,354.0 L753.0,342.0 737.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4bb57a53bbe545b982cfaa9627766ad9-0-5\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4bb57a53bbe545b982cfaa9627766ad9-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1085.0,354.0 L1093.0,342.0 1077.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4bb57a53bbe545b982cfaa9627766ad9-0-6\" stroke-width=\"2px\" d=\"M945,352.0 C945,177.0 1265.0,177.0 1265.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4bb57a53bbe545b982cfaa9627766ad9-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1265.0,354.0 L1273.0,342.0 1257.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy.displacy.render(doc, style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Maria Sharapova has basically no friends as tennis players on the WTA Tour. The Russian player has no problems in openly speaking about it and in a recent interview she said: 'I don't really hide any feelings too much.\n",
    "I think everyone knows this is my job here. When I'm on the courts or when I'm on the court playing, I'm a competitor and I want to beat every single person whether they're in the locker room or across the net.\n",
    "So I'm not the one to strike up a conversation about the weather and know that in the next few minutes I have to go and try to win a tennis match. I'm a pretty competitive girl. I say my hellos, but I'm not sending any players flowers as well.\n",
    "Uhm, I'm not really friendly or close to many players. I have not a lot of friends away from the courts.' When she said she is not really close to a lot of players, is that something strategic that she is doing? Is it different on the men's tour than the women's tour? 'No, not at all.\n",
    "I think just because you're in the same sport doesn't mean that you have to be friends with everyone just because you're categorized, you're a tennis player, so you're going to get along with tennis players.\n",
    "I think every person has different interests. I have friends that have completely different jobs and interests, and I've met them in very different parts of my life. I think everyone just thinks because we're tennis players we should be the greatest of friends.\n",
    "But ultimately tennis is just a very small part of what we do. There are so many other things that we're interested in, that we do.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maria Sharapova PERSON\n",
      "the WTA Tour ORG\n",
      "Russian NORP\n",
      "the next few minutes TIME\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp_sm = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def create_word_counts_by_pos(raw_text, list_of_pos, word_count_dict_input = None):\n",
    "    \"\"\"\n",
    "    takes a raw text file\n",
    "    tokenizes and lemmatizes it\n",
    "    limits inspection to list_of_pos types of words\n",
    "    counts the individual lemmas\n",
    "    returns a dictionary, keys are pos's in list_of_pos\n",
    "    values are dictinaries with word counts\n",
    "    \"\"\"\n",
    "\n",
    "    doc = nlp_sm(raw_text)\n",
    "\n",
    "    if word_count_dict_input is None: \n",
    "        word_count_dict = {}\n",
    "        for part_of_speech in list_of_pos:\n",
    "            word_count_dict[part_of_speech] = {}\n",
    "    else:\n",
    "        word_count_dict = word_count_dict_input\n",
    "\n",
    "    for token in doc: \n",
    "        part_of_speech = token.pos_\n",
    "\n",
    "        if part_of_speech in list_of_pos and token.is_stop == False:\n",
    "            word_lemma = token.lemma_\n",
    "            current_count = word_count_dict[part_of_speech].get(word_lemma, 0)\n",
    "            current_count += 1\n",
    "            word_count_dict[part_of_speech][word_lemma] = current_count\n",
    "\n",
    "    return word_count_dict\n",
    "\n",
    "def filter_word_count_dict_to_frequent(word_count_dict, threshold):\n",
    "    \"\"\"\n",
    "    Loops through word_count_dict, only keeps items where \n",
    "    value is higher than a certain threshold\n",
    "    \"\"\"\n",
    "    frequent_word_count_dict = {}\n",
    "\n",
    "    list_of_pos = word_count_dict.keys()\n",
    "\n",
    "    for part_of_speech in list_of_pos:\n",
    "        frequent_word_count_dict[part_of_speech] = {}\n",
    "        for key in word_count_dict[part_of_speech]:\n",
    "            if word_count_dict[part_of_speech][key] > threshold:\n",
    "                frequent_word_count_dict[part_of_speech][key] = \\\n",
    "                word_count_dict[part_of_speech][key]\n",
    "                \n",
    "    return frequent_word_count_dict\n",
    "\n",
    "def collect_most_frequent_words(word_count_dict, number_to_collect):\n",
    "    \"\"\"\n",
    "    word_count_dict is assumed to be in a format where keys are part-of-speech, \n",
    "    values are counts\n",
    "    number_of_collect: we will collect this amount from each group\n",
    "    if there is a tie: the one that appeared first\n",
    "    \"\"\"\n",
    "\n",
    "    list_of_pos = word_count_dict.keys()\n",
    "    most_frequent_words = {}\n",
    "\n",
    "    for part_of_speech in list_of_pos:\n",
    "        most_frequent_words[part_of_speech] = \\\n",
    "        sorted(word_count_dict[part_of_speech].items(), \\\n",
    "            key=lambda x: x[1], reverse = True)[:number_to_collect] \n",
    "        \n",
    "    return most_frequent_words\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_pos = ['NOUN', 'PROPN', 'ADJ', 'VERB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count_dict = create_word_counts_by_pos(text, list_of_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NOUN': {'friend': 5,\n",
       "  'tennis': 6,\n",
       "  'player': 8,\n",
       "  'problem': 1,\n",
       "  'interview': 1,\n",
       "  'feeling': 1,\n",
       "  'job': 2,\n",
       "  'court': 3,\n",
       "  'playing': 1,\n",
       "  'competitor': 1,\n",
       "  'person': 2,\n",
       "  'locker': 1,\n",
       "  'room': 1,\n",
       "  'net': 1,\n",
       "  'conversation': 1,\n",
       "  'weather': 1,\n",
       "  'minute': 1,\n",
       "  'match': 1,\n",
       "  'girl': 1,\n",
       "  'hello': 1,\n",
       "  'flower': 1,\n",
       "  'lot': 2,\n",
       "  'man': 1,\n",
       "  'tour': 2,\n",
       "  'woman': 1,\n",
       "  'sport': 1,\n",
       "  'interest': 2,\n",
       "  'part': 1,\n",
       "  'life': 1,\n",
       "  'thing': 1},\n",
       " 'PROPN': {'Maria': 1, 'Sharapova': 1, 'WTA': 1, 'Tour': 1, 'Uhm': 1},\n",
       " 'ADJ': {'russian': 1,\n",
       "  'recent': 1,\n",
       "  'single': 1,\n",
       "  'competitive': 1,\n",
       "  'friendly': 1,\n",
       "  'close': 2,\n",
       "  'strategic': 1,\n",
       "  'different': 4,\n",
       "  'great': 1,\n",
       "  'small': 1,\n",
       "  'interested': 1},\n",
       " 'VERB': {'speak': 1,\n",
       "  'say': 2,\n",
       "  'hide': 1,\n",
       "  'think': 5,\n",
       "  'know': 2,\n",
       "  'want': 1,\n",
       "  'beat': 1,\n",
       "  'strike': 1,\n",
       "  'try': 1,\n",
       "  'win': 1,\n",
       "  'send': 1,\n",
       "  'mean': 1,\n",
       "  'categorize': 1,\n",
       "  'go': 1,\n",
       "  'meet': 1}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequent_word_count_dict = filter_word_count_dict_to_frequent(word_count_dict, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NOUN': {}, 'PROPN': {}, 'ADJ': {}, 'VERB': {}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_word_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_words_to_collect = 5\n",
    "list_of_pos = ['NOUN', 'ADJ', 'VERB']\n",
    "words = {}\n",
    "word_counts = {}\n",
    "for part_of_speech in list_of_pos:\n",
    "    words[part_of_speech] = {}\n",
    "    word_counts[part_of_speech] = {}\n",
    "    for number in range(number_of_words_to_collect):\n",
    "        words[part_of_speech][number] = []\n",
    "        word_counts[part_of_speech][number] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filenames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-852d4837231e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mmy_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxt_adjusted_folder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Currently processing: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mraw_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     word_count_dict = create_word_counts_by_pos(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filenames' is not defined"
     ]
    }
   ],
   "source": [
    "for filename in filenames: \n",
    "    my_file = open(txt_adjusted_folder + filename + '.txt')\n",
    "    print(\"Currently processing: \" + filename)\n",
    "    raw_text = my_file.read()\n",
    "    word_count_dict = create_word_counts_by_pos(\n",
    "            raw_text, list_of_pos)\n",
    "    most_frequent_list_dict = collect_most_frequent_words(\n",
    "            word_count_dict, number_of_words_to_collect)\n",
    "    for part_of_speech in list_of_pos:\n",
    "        for number in range(number_of_words_to_collect):\n",
    "            words[part_of_speech][number].append(\n",
    "                most_frequent_list_dict[part_of_speech][number][0])\n",
    "            word_counts[part_of_speech][number].append(\n",
    "                most_frequent_list_dict[part_of_speech][number][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Indonesia merupakan negara kepulauan yang kaya akan budaya.\",\n",
    "    \"Berapa banyak warga yang dibutuhkan saat kerja bakti?\",\n",
    "    \"Penyaluran pupuk berasal dari lima lokasi yakni Bontang, Kalimantan Timur, Surabaya, Banyuwangi, Semarang, dan Makassar.\",\n",
    "    \"PT Pupuk Kaltim telah menyalurkan 274.707 ton pupuk bersubsidi ke wilayah penyaluran di 14 provinsi.\",\n",
    "    \"Jakarta adalah kota besar yang nyaris tidak pernah tidur.\"\n",
    "    \"Kamu ada di mana semalam?\",\n",
    "    \"Siapa yang membeli makanan ringan tersebut?\",\n",
    "    \"Siapa presiden pertama Republik Indonesia?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from spacy.lang.id.examples import sentences\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "docs = nlp.pipe(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Language.pipe at 0x0000019E92FCC4F8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
