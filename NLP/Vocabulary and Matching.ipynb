{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Rule-based matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import the Matcher library\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab) #create matcher object and pass nlp.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here matcher is an object that pairs to current Vocab object\n",
    "#### We can add and remove specific named matcheers to matcher as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list, and inside that list add series of dictionaries\n",
    "# Hello World caan appear in the following ways,\n",
    "# 1) Hello World hello world Hellow WORLD\n",
    "# 2) Hello-World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern_1 = [{'LOWER':'hello'},{'LOWER':'world'}]\n",
    "pattern_2 = [{'LOWER':'hello'},{'IS_PUNCT':True},{'LOWER':'world'}]\n",
    "pattern = [{'LOWER':\"hello\"},{\"LOWER\":\"world\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add patterns to matcher object\n",
    "\n",
    "#Add a match rule to matcher, A match rule consists of,\n",
    "# 1) An ID Key\n",
    "# 2) An on_match callback\n",
    "# 3) one or more patterns\n",
    "\n",
    "###matcher.add('Hello World',pattern_2)\n",
    "matcher.add(\"Hello World\",[pattern_1,pattern_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"'Hello World' are the first two printed words for most of the programmers, printing 'Hello-World' is most common \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World' are the first two printed words for most of the programmers, printing 'Hello-World' is most common "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(15578876784678163569, 1, 3), (8585552006568828647, 1, 3), (8585552006568828647, 18, 21)]\n"
     ]
    }
   ],
   "source": [
    "#pass in doc to matcher object and store thiss in a variable\n",
    "find_matches = matcher(doc)\n",
    "print(find_matches)\n",
    "\n",
    "\n",
    "#it returns output list of tuples\n",
    "#string ID, index start and index end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15578876784678163569 HelloWorld 1 3 Hello World\n",
      "8585552006568828647 Hello World 1 3 Hello World\n",
      "8585552006568828647 Hello World 18 21 Hello-World\n"
     ]
    }
   ],
   "source": [
    "# define a function to find the matches\n",
    "for match_id,start,end in find_matches:\n",
    "    string_id = nlp.vocab.strings[match_id] #get string representation\n",
    "    span = doc[start:end]\n",
    "    print(match_id,string_id,start,end,span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remov the matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matcher.remove('Hello World')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting pattern options and quantifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Redefine the patterns:\n",
    "pattern_3 = [{'LOWER':'hello'},{'LOWER':'world'}]\n",
    "pattern_4 = [{'LOWER':'hellow'},{'IS_PUNCT':True},{'OP':'*'},{'LOWER':'world'}]\n",
    "\n",
    "#'OP:'*'  ---->   This is going to allow this pattern to match zero or more times for any punctuation\n",
    "\n",
    "#Add the new set of patterns to the 'Hello World' matcher\n",
    "matcher.add('Hello World',[pattern_3,pattern_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc2 = nlp('You can print Hello World or hello world or Hello-World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(15578876784678163569, 3, 5), (8585552006568828647, 3, 5), (15578876784678163569, 6, 8), (8585552006568828647, 6, 8)]\n"
     ]
    }
   ],
   "source": [
    "find_matches = matcher(doc2)\n",
    "print(find_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Phase Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the PhraseMatcher library\n",
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phrase_list = ['Barack Obama','Angela Markel','Washington, D.C.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert each phrase to a document object\n",
    "phrase_patterns = [nlp(text) for text in phrase_list] # to do that we are using list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Barack Obama, Angela Markel, Washington, D.C.]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#phrase objects are not strings\n",
    "phrase_patterns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama\n",
      "<class 'spacy.tokens.doc.Doc'>\n",
      "Angela Markel\n",
      "<class 'spacy.tokens.doc.Doc'>\n",
      "Washington, D.C.\n",
      "<class 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "for i in phrase_patterns:\n",
    "    print(i)\n",
    "    print(type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pass each doc object into matcher\n",
    "# thats we have to add asterisk mark before phrase_pattern\n",
    "matcher.add('TerminologyList',None,*phrase_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc3 = nlp('German Chancellor Angela Merkel and US President Barack Obama '\n",
    "          'converse in the Oval Office inside the White House in Washington, D.C. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3766102292120407359, 7, 9), (3766102292120407359, 19, 22)]\n"
     ]
    }
   ],
   "source": [
    "# pass in doc to another object and store this in a variable\n",
    "find_matches = matcher(doc3)\n",
    "print(find_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3766102292120407359 TerminologyList 7 9 Barack Obama\n",
      "3766102292120407359 TerminologyList 19 22 Washington, D.C.\n"
     ]
    }
   ],
   "source": [
    "# define a function to find the matches\n",
    "for match_id,start,end in find_matches:\n",
    "    string_id = nlp.vocab.strings[match_id] # get string representation\n",
    "    span = doc3[start:end]\n",
    "    print(match_id,string_id,start,end,span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
