{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = 'This is a sentence. This is second sentence. This is last sentence.'\n",
    "s2 = 'This is a sentence; This is second sentence; This is last sentence.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(name='en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc1 = nlp(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence.\n",
      "This is second sentence.\n",
      "This is last sentence.\n"
     ]
    }
   ],
   "source": [
    "# Identify sentence in paragraph\n",
    "\n",
    "for sent in doc1.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Example 2\n",
    "#got special character .\n",
    "\n",
    "s3 = 'This is a sentence. This is second U.K. sentence. This is last sentence.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc3 = nlp(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence.\n",
      "This is second U.K. sentence.\n",
      "This is last sentence.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc3.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence; This is second sentence; This is last sentence.\n",
      "This is a sentence; This is second sentence; This is last sentence.\n"
     ]
    }
   ],
   "source": [
    "#Example 3 - paragrah with ; to separate sentence\n",
    "print(s2)\n",
    "doc2 = nlp(s2)\n",
    "for sent in doc2.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how to make it recognize semicolon to separate sentence\n",
    "#### notice that in s2, first 2 sentences end with semicolon, last one end with full stop\n",
    "\n",
    "### Function: set_custom_boundaries \n",
    "#### remove last token\n",
    "#### whenever encounter ;, the token afterward is the starting point of new sent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.set_custom_boundaries(doc)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register a custom pipeline component under a given name\n",
    "# allows initializing the component by name using Language.add_pipe\n",
    "\n",
    "from spacy.language import Language\n",
    "\n",
    "@Language.component('set_custom_boundaries')\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == ';':\n",
    "            print(token.i)\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "Language.component('set_custom_boundaries',func=set_custom_boundaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check current pipeline componenst\n",
    "\n",
    "#### text > NLP(tokenizer,tagger,parser,ner...) > Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x1c3efa61d08>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x1c3efa61c48>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1c3ee867978>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x1c3ee867588>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x1c3efc542c8>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x1c3efc453c8>)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.set_custom_boundaries(doc)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add custom function to pipeline so that before parser, will perform the defined step first\n",
    "#nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('set_custom_boundaries',before='parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'set_custom_boundaries',\n",
       " 'parser',\n",
       " 'ner',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence; This is second sentence; This is last sentence.\n",
      "4\n",
      "9\n",
      "This is a sentence;\n",
      "This is second sentence;\n",
      "This is last sentence.\n"
     ]
    }
   ],
   "source": [
    "print(s2)\n",
    "doc2 = nlp(s2)\n",
    "for sent in doc2.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
